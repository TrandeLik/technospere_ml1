{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "802Qky6jLrr7"
   },
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wVvGsd9Lrr9"
   },
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 13 июня 2022, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 13 июня, -4 балла после 08:30 20 июня, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0422, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00j9_nZyLrr-"
   },
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xleNGtzqLrr-"
   },
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti67CxbLLrr_"
   },
   "source": [
    "Рассматриваем j-ю итерацию бустинга ($F^j(x_i)$)\n",
    "1) MSE\n",
    "$$target_j = -\\frac{\\partial L(F^{j-1}(x_i), y_i)}{\\partial F^{j-1}(x_i)} = 2(y_i - F^{j-1}(x_i))$$\n",
    "2) Экспоненциальная\n",
    "$$target_j = -\\frac{\\partial L(F^{j-1}(x_i), y_i)}{\\partial F^{j-1}(x_i)} = y_i e^{-F^{j-1}(x_i)y_i}$$\n",
    "3) Логистическая\n",
    "$$target_j = -\\frac{\\partial L(F^{j-1}(x_i), y_i)}{\\partial F^{j-1}(x_i)} = \\frac{y_i e^{-F^{j-1}(x_i)y_i}}{1 + e^{-F^{j-1}(x_i)y_i}} = \\frac{y_i}{1 + e^{F^{j-1}(x_i)y_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R1tYhXgLrr_"
   },
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENi-woiqLrsA"
   },
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuYRtGzALrsA"
   },
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qW9fsR7lLrsB",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QpNocbcBLrsC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss=\"log_loss\", learning_rate=0.1, n_estimators=100, colsample=1.0, subsample=0.1, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        subsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.model_args = args\n",
    "        self.model_kwargs = kwargs\n",
    "        self.__targets = {\n",
    "                            \"mse\"      : self.__mse_target,\n",
    "                            \"exp\"      : self.__exp_target,\n",
    "                            \"log_loss\" : self.__log_loss_target\n",
    "                         }\n",
    "        self.__models = []\n",
    "        self.__features_history = []\n",
    "        self.__dimension = 1\n",
    "        \n",
    "    def __mse_target(self, preds, y_true):\n",
    "        \"\"\"\n",
    "        Целевая переменная для MSE\n",
    "        \"\"\"\n",
    "        return 2 * (y_true - preds)\n",
    "    \n",
    "    def __exp_target(self, preds, y_true):\n",
    "        \"\"\"\n",
    "        Целевая переменная для экспоненциальной функции потерь\n",
    "        \"\"\"\n",
    "        return y_true * np.exp(-preds * y_true)\n",
    "    \n",
    "    def __log_loss_target(self, preds, y_true):\n",
    "        \"\"\"\n",
    "        Целевая переменная для логической\n",
    "        \"\"\"\n",
    "        return y_true / (1. + np.exp(preds * y_true))\n",
    "    \n",
    "    def __run_init_model(self, X, y, init_model):\n",
    "        \"\"\"\n",
    "        Запуск инициирующей модели\n",
    "        \"\"\"\n",
    "        if init_model != None:\n",
    "            init_model.fit(X, y)\n",
    "            self.__models.append(init_model)\n",
    "            self.__features_history.append(np.arange(X.shape[1]))\n",
    "            return init_model.predict(X)\n",
    "        else:\n",
    "            if y.shape[0] != y.size:\n",
    "                self.__dimension = y.shape[1]\n",
    "                return np.zeros((y.shape[0], y.shape[1]))\n",
    "            else:\n",
    "                return np.zeros(y.shape[0])\n",
    "        return None\n",
    "    \n",
    "    def __transform_target(self, y):\n",
    "        \"\"\"\n",
    "        Преобразование таргета\n",
    "        Для mse приводим к, возможно, многоклассовой классификации\n",
    "        Для остальных преобразуем в -1, 1\n",
    "        P.S. без этого не получилось выбить нужный скор\n",
    "        \"\"\"\n",
    "        if self.loss != \"mse\":\n",
    "            return 2 * y - 1 \n",
    "        else:\n",
    "            classes = np.unique(y)\n",
    "            new_y = np.zeros((y.shape[0], classes.shape[0]))\n",
    "            for i, j in enumerate(y):\n",
    "                new_y[i, j] = 1\n",
    "            return new_y\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для последнего задания)\n",
    "        \"\"\"\n",
    "        y = self.__transform_target(y)\n",
    "        current_preds = self.__run_init_model(X, y, init_model)\n",
    "        number_of_features = int(X.shape[1] * self.colsample)\n",
    "        number_of_objects = int(X.shape[0] * self.subsample)\n",
    "        for iteration in range(self.n_estimators):\n",
    "            features = np.random.choice(X.shape[1], number_of_features, replace=False) \n",
    "            objects = np.random.choice(X.shape[0], number_of_objects)\n",
    "            target = self.__targets[self.loss](current_preds[objects], y[objects])\n",
    "            model = base_model(*self.model_args, **self.model_kwargs)\n",
    "            model.fit(X[objects][:, features], target)\n",
    "            self.__models.append(model)\n",
    "            self.__features_history.append(features)\n",
    "            current_preds += self.learning_rate * model.predict(X[:, features])\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.__dimension != 1:\n",
    "            preds = np.zeros((X.shape[0], self.__dimension))\n",
    "        else:\n",
    "            preds = np.zeros(X.shape[0])\n",
    "        for i, model in enumerate(self.__models):\n",
    "            preds += self.learning_rate * model.predict(X[:, self.__features_history[i]])\n",
    "        if self.loss == \"mse\":\n",
    "            return softmax(preds, axis=1).argmax(axis=1)\n",
    "        return (preds > 0).astype('int')\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"\n",
    "        Для совместимости с sklearn-функциями\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"loss\"          : self.loss,\n",
    "            \"learning_rate\" : self.learning_rate,\n",
    "            \"n_estimators\"  : self.n_estimators,\n",
    "            \"colsample\"     : self.colsample,\n",
    "            \"subsample\"     : self.subsample\n",
    "        }\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Для совместимости с sklearn-функциями\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                self.model_kwargs[key] = value\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "khRja5GMLrsI"
   },
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss=\"mse\")\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nL_9SObiLrsI",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7xMXVlHLrsI",
    "outputId": "97853aaa-87ec-4389-ccb6-600cfde0f34f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDSvWqt0LrsJ"
   },
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xtD-YJaLrsJ"
   },
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TxmfpdTJLrsK"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GVnCgulLrsK",
    "outputId": "f64c480d-49ed-4ea3-f1e5-c94ef57f36db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_botc20rLrsK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0TMEDviqLrsL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ShkPPabkLrsL"
   },
   "outputs": [],
   "source": [
    "n_estimators = [10, 50, 100, 250, 500, 750, 1000, 1250, 1500]\n",
    "scores = []\n",
    "for i in n_estimators:\n",
    "    s = cross_val_score(MyGradientBoostingClassifier(n_estimators=i), X, y, cv=3, scoring=\"accuracy\")\n",
    "    scores.append(s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "lCAHw-QALrsL",
    "outputId": "9ec4a79a-8967-471d-d263-fd7843884de0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(n_estimators, scores)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id5s6lefLrsM"
   },
   "source": [
    "Оптимальное количество - 1250 итераций. Подберем оптимальные параметры с помощью RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7zypKH0mLrsM"
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"loss\": (\"mse\", \"log_loss\", \"exp\"),\n",
    "    \"learning_rate\": (0.1, 0.05, 0.01, 0.005),\n",
    "    \"colsample\": (0.5, 0.7, 0.9),\n",
    "    \"subsample\": (0.5, 0.7, 0.9),\n",
    "    \"max_depth\": (3, 5, 7)\n",
    "}\n",
    "search = RandomizedSearchCV(MyGradientBoostingClassifier(n_estimators=1250), \n",
    "                            grid, verbose=3, cv=3, scoring=\"accuracy\", n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_qoeNBALrsM",
    "outputId": "00717d77-5a54-40b9-f089-5d04f247ee56",
    "scrolled": true
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV 1/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=5, subsample=0.7;, score=0.782 total time=  36.7s\n",
      "[CV 2/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=5, subsample=0.7;, score=0.836 total time=  34.2s\n",
      "[CV 3/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=5, subsample=0.7;, score=0.785 total time=  35.5s\n",
      "[CV 1/3] END colsample=0.5, learning_rate=0.05, loss=exp, max_depth=5, subsample=0.7;, score=0.812 total time=  28.0s\n",
      "[CV 2/3] END colsample=0.5, learning_rate=0.05, loss=exp, max_depth=5, subsample=0.7;, score=0.859 total time=  29.0s\n",
      "[CV 3/3] END colsample=0.5, learning_rate=0.05, loss=exp, max_depth=5, subsample=0.7;, score=0.798 total time=  25.9s\n",
      "[CV 1/3] END colsample=0.9, learning_rate=0.05, loss=exp, max_depth=7, subsample=0.9;, score=0.807 total time= 1.2min\n",
      "[CV 2/3] END colsample=0.9, learning_rate=0.05, loss=exp, max_depth=7, subsample=0.9;, score=0.862 total time= 1.2min\n",
      "[CV 3/3] END colsample=0.9, learning_rate=0.05, loss=exp, max_depth=7, subsample=0.9;, score=0.813 total time= 1.2min\n",
      "[CV 1/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=3, subsample=0.9;, score=0.771 total time=  22.1s\n",
      "[CV 2/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=3, subsample=0.9;, score=0.850 total time=  22.1s\n",
      "[CV 3/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=3, subsample=0.9;, score=0.745 total time=  22.0s\n",
      "[CV 1/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=5, subsample=0.7;, score=0.806 total time=  43.0s\n",
      "[CV 2/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=5, subsample=0.7;, score=0.859 total time=  42.8s\n",
      "[CV 3/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=5, subsample=0.7;, score=0.801 total time=  43.0s\n",
      "[CV 1/3] END colsample=0.7, learning_rate=0.005, loss=mse, max_depth=7, subsample=0.7;, score=0.810 total time=  44.7s\n",
      "[CV 2/3] END colsample=0.7, learning_rate=0.005, loss=mse, max_depth=7, subsample=0.7;, score=0.862 total time=  45.0s\n",
      "[CV 3/3] END colsample=0.7, learning_rate=0.005, loss=mse, max_depth=7, subsample=0.7;, score=0.789 total time=  44.4s\n",
      "[CV 1/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=3, subsample=0.7;, score=0.774 total time=  23.7s\n",
      "[CV 2/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=3, subsample=0.7;, score=0.850 total time=  22.6s\n",
      "[CV 3/3] END colsample=0.7, learning_rate=0.1, loss=mse, max_depth=3, subsample=0.7;, score=0.798 total time=  22.5s\n",
      "[CV 1/3] END colsample=0.9, learning_rate=0.1, loss=log_loss, max_depth=7, subsample=0.5;, score=0.806 total time=  41.6s\n",
      "[CV 2/3] END colsample=0.9, learning_rate=0.1, loss=log_loss, max_depth=7, subsample=0.5;, score=0.860 total time=  41.7s\n",
      "[CV 3/3] END colsample=0.9, learning_rate=0.1, loss=log_loss, max_depth=7, subsample=0.5;, score=0.813 total time=  41.3s\n",
      "[CV 1/3] END colsample=0.7, learning_rate=0.05, loss=log_loss, max_depth=7, subsample=0.7;, score=0.803 total time=  42.6s\n",
      "[CV 2/3] END colsample=0.7, learning_rate=0.05, loss=log_loss, max_depth=7, subsample=0.7;, score=0.864 total time=  41.8s\n",
      "[CV 3/3] END colsample=0.7, learning_rate=0.05, loss=log_loss, max_depth=7, subsample=0.7;, score=0.794 total time=  41.5s\n",
      "[CV 1/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=5, subsample=0.5;, score=0.791 total time=  19.1s\n",
      "[CV 2/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=5, subsample=0.5;, score=0.855 total time=  19.1s\n",
      "[CV 3/3] END colsample=0.5, learning_rate=0.01, loss=log_loss, max_depth=5, subsample=0.5;, score=0.760 total time=  19.1s\n",
      "[CV 1/3] END colsample=0.9, learning_rate=0.01, loss=mse, max_depth=5, subsample=0.7;, score=0.783 total time=  46.2s\n",
      "[CV 2/3] END colsample=0.9, learning_rate=0.01, loss=mse, max_depth=5, subsample=0.7;, score=0.864 total time=  45.5s\n",
      "[CV 3/3] END colsample=0.9, learning_rate=0.01, loss=mse, max_depth=5, subsample=0.7;, score=0.815 total time=  45.2s\n",
      "[CV 1/3] END colsample=0.5, learning_rate=0.1, loss=log_loss, max_depth=5, subsample=0.5;, score=0.808 total time=  19.3s\n",
      "[CV 2/3] END colsample=0.5, learning_rate=0.1, loss=log_loss, max_depth=5, subsample=0.5;, score=0.861 total time=  19.3s\n",
      "[CV 3/3] END colsample=0.5, learning_rate=0.1, loss=log_loss, max_depth=5, subsample=0.5;, score=0.795 total time=  19.2s\n",
      "[CV 1/3] END colsample=0.7, learning_rate=0.01, loss=log_loss, max_depth=7, subsample=0.7;, score=0.801 total time=  42.3s\n",
      "[CV 2/3] END colsample=0.7, learning_rate=0.01, loss=log_loss, max_depth=7, subsample=0.7;, score=0.857 total time=  41.5s\n",
      "[CV 3/3] END colsample=0.7, learning_rate=0.01, loss=log_loss, max_depth=7, subsample=0.7;, score=0.777 total time=  41.1s\n",
      "[CV 1/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=7, subsample=0.5;, score=0.804 total time=  41.4s\n",
      "[CV 2/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=7, subsample=0.5;, score=0.859 total time=  41.4s\n",
      "[CV 3/3] END colsample=0.9, learning_rate=0.01, loss=exp, max_depth=7, subsample=0.5;, score=0.807 total time=  41.1s\n",
      "[CV 1/3] END colsample=0.5, learning_rate=0.05, loss=mse, max_depth=3, subsample=0.7;, score=0.804 total time=  21.5s\n",
      "[CV 2/3] END colsample=0.5, learning_rate=0.05, loss=mse, max_depth=3, subsample=0.7;, score=0.860 total time=  19.2s\n",
      "[CV 3/3] END colsample=0.5, learning_rate=0.05, loss=mse, max_depth=3, subsample=0.7;, score=0.783 total time=  19.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<__main__.MyGradientBoostingClassifier object at 0x7f7e31188d10>,\n",
       "                   n_iter=15,\n",
       "                   param_distributions={'colsample': (0.5, 0.7, 0.9),\n",
       "                                        'learning_rate': (0.1, 0.05, 0.01,\n",
       "                                                          0.005),\n",
       "                                        'loss': ('mse', 'log_loss', 'exp'),\n",
       "                                        'max_depth': (3, 5, 7),\n",
       "                                        'subsample': (0.5, 0.7, 0.9)},\n",
       "                   scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIldGu6ILrsM",
    "outputId": "e9ae969f-03fe-466e-f144-80214ce77dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample': 0.9,\n",
       "  'learning_rate': 0.05,\n",
       "  'loss': 'exp',\n",
       "  'max_depth': 7,\n",
       "  'subsample': 0.9},\n",
       " 0.8271317829457364)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K86YfQHcLrsN"
   },
   "source": [
    "Скор на валидации у лучшей модели - 0.8271\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zekQAvoKLrsN"
   },
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3mXc38lLrsN"
   },
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MnXleZpLrsN"
   },
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zA5STHWwLrsN",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UgCo0OhLrsO",
    "outputId": "d87f9fe7-2c05-4da0-d23a-2c8c31ca4d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184108527131783\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=3)\n",
    "result = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model = MyGradientBoostingClassifier(loss ='exp', n_estimators=40,\n",
    "                                         learning_rate=0.1, colsample=0.7, subsample=0.7)\n",
    "    model.fit(X[train_index], y[train_index], base_model=RandomForestRegressor)\n",
    "    result.append(accuracy_score(y[test_index], model.predict(X[test_index])))\n",
    "print(np.mean(np.array(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "j2wfNB-6LrsP"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EAQAJ2d6LrsP"
   },
   "outputs": [],
   "source": [
    "model = MyGradientBoostingClassifier(loss ='exp', n_estimators=80,\n",
    "                                         learning_rate=0.1, colsample=0.7, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICZU-lo1LrsP",
    "outputId": "17dbec83-5678-4202-b6e0-22a3bb12fb06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510174418604652"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(BaggingClassifier(base_estimator=model, n_estimators=10),\n",
    "                        X, y, cv=3, scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqb6wUtUY25o"
   },
   "source": [
    "В случае бустинга качество немного упало. Скорее всего, это вызвано тем, что плохо подобраны параметры модели в этом случае, к томе же количество моделей в этом случае небольшое. Но в то же время, возможно, мы исчерпали обобщающую способность на этих данных обычными деревьями\n",
    "\n",
    "В случае бэгинга над бустингом качество заметно упало. Скорее всего, это вызвано плохим подбором параметров. Также, вполне возможно переобучение\n",
    "\n",
    "**Замечание**: более детальный подбор параметров или большее количество моделей использовать не получилось, так как не влезал в доступную оперативку :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkJmPX0NLrsQ"
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "g9SPTLi1LrsQ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQrDyxuwLrsQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "791d5aba-fe43-4507-e150-44fe054d2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8186046511627908\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=3)\n",
    "result = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model = MyGradientBoostingClassifier(loss ='exp', n_estimators=1250,\n",
    "                                         learning_rate=0.05, colsample=0.9, subsample=0.9)\n",
    "    model.fit(X[train_index], y[train_index], init_model=RandomForestRegressor())\n",
    "    result.append(accuracy_score(y[test_index], model.predict(X[test_index])))\n",
    "print(np.mean(np.array(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFcYQUuTYl3b",
    "outputId": "a26f5445-9f02-470b-cdc1-d8b8a8fb3d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8147771317829458\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=3)\n",
    "result = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model = MyGradientBoostingClassifier(loss ='exp', n_estimators=1250,\n",
    "                                         learning_rate=0.05, colsample=0.9, subsample=0.9)\n",
    "    model.fit(X[train_index], y[train_index], init_model=LinearRegression())\n",
    "    result.append(accuracy_score(y[test_index], model.predict(X[test_index])))\n",
    "print(np.mean(np.array(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqv2CChAYmED",
    "outputId": "1c422296-605a-406c-ebda-91a44b6888f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160368217054264\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=3)\n",
    "result = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model = MyGradientBoostingClassifier(loss ='exp', n_estimators=1250,\n",
    "                                         learning_rate=0.05, colsample=0.9, subsample=0.9)\n",
    "    model.fit(X[train_index], y[train_index], init_model=SVR())\n",
    "    result.append(accuracy_score(y[test_index], model.predict(X[test_index])))\n",
    "print(np.mean(np.array(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KAKXOixYzhU"
   },
   "source": [
    "Качество улучшить не получилось. Скорее всего, это связано с тем, что под эти модели не были подобраны оптимальные параметры, но в то же время возможно, что более сильные модели в инициализации приводили к тому, что базовые модели хуже обучались и, как следствие, падала точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H2DQ61-LrsQ"
   },
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emg1xoebLrsR"
   },
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PqO1DqoLrsR"
   },
   "source": [
    "Ансамбли были очень хорошо расказаны!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR_Kcc3vLrsR"
   },
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2ucUYj7LrsR"
   },
   "source": [
    "Было бы круто иметь альтернативные данные, чтобы нормально разобраться с BooBag и BagBoo, а не получать переполнение оперативки при любом движении\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ek6t8LGILrsR",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZbVQdMVULrsS",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
